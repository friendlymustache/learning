dynamic
programming
dynamic
solves
problems
combining
solutions
context
refers
tabular
writing
computer
saw
chapters
algorithms
partition
problem
disjoint
solve
subproblems
combine
solutions
solve
original
dynamic
programming
applies
lems
subproblems
share
algorithm
does
work
repeatedly
ing
common
algorithm
solves
subsubproblem
just
once
saves
answer
thereby
avoiding
work
recomputing
answer
every
time
solves
typically
apply
dynamic
programming
optimization
lems
many
possible
solution
has
wish
solution
optimal
call
solution
optimal
solution
opposed
optimal
may
several
solutions
achieve
optimal
developing
follow
sequence
four
characterize
structure
optimal
recursively
value
optimal
compute
value
optimal
typically
construct
optimal
solution
computed
steps
form
basis
solution
need
value
optimal
solution
omit
step
perform
step
sometimes
maintain
additional
information
step
easily
construct
optimal
sections
follow
use
method
solve
optimization
section
examines
problem
cutting
rod
chapter
dynamic
programming
rods
smaller
length
way
maximizes
total
section
asks
multiply
chain
matrices
while
performing
fewest
total
scalar
given
examples
dynamic
section
cusses
two
key
characteristics
problem
must
dynamic
programming
viable
solution
section
shows
longest
common
subsequence
two
sequences
dynamic
tion
uses
dynamic
programming
construct
binary
search
trees
given
known
distribution
keys
looked
rod
cutting
example
uses
dynamic
programming
solve
simple
problem
ing
cut
steel
serling
enterprises
buys
long
steel
rods
cuts
them
shorter
cut
management
serling
enterprises
wants
know
best
way
cut
assume
price
pi
dollars
serling
enterprises
charges
rod
length
rod
lengths
always
integral
number
figure
gives
sample
price
problem
given
rod
length
inches
table
prices
pi
determine
maximum
revenue
rn
able
cutting
rod
selling
note
price
pn
rod
length
large
optimal
solution
may
require
no
cutting
consider
case
figure
shows
ways
cut
rod
inches
including
way
no
cuts
cutting
rod
two
pieces
produces
revenue
cut
rod
length
different
dependent
option
distance
inches
left
length
price
pi
figure
sample
price
table
rod
length
inches
earns
company
pi
dollars
rod
cutting
figure
possible
ways
cutting
rod
length
piece
value
according
sample
price
chart
figure
optimal
strategy
part
rod
two
pieces
length
has
total
value
denote
decomposition
pieces
using
ordinary
additive
indicates
rod
length
cut
three
length
one
length
optimal
solution
cuts
rod
optimal
decomposition
ik
rod
pieces
lengths
ik
provides
maximum
corresponding
revenue
rn
pik
sample
determine
optimal
revenue
ri
corresponding
optimal
decompositions
required
pieces
cut
order
nondecreasing
would
fewer
ways
would
consider
parts
figure
number
ways
called
partition
approximately
equal
quantity
less
still
much
greater
any
polynomial
shall
pursue
line
inquiry
chapter
dynamic
programming
solution
solution
solution
solution
solution
solution
solution
solution
solution
solution
frame
values
rn
terms
optimal
enues
shorter
rn
max
corresponds
making
no
cuts
selling
rod
length
arguments
max
correspond
maximum
enue
obtained
making
initial
cut
rod
two
pieces
size
optimally
cutting
those
pieces
obtaining
revenues
ri
those
two
know
ahead
time
value
optimizes
consider
possible
values
pick
one
maximizes
option
picking
no
obtain
revenue
selling
rod
note
solve
original
problem
size
solve
smaller
problems
smaller
once
make
may
consider
two
pieces
independent
instances
overall
optimal
solution
incorporates
optimal
solutions
two
related
maximizing
revenue
those
two
say
problem
exhibits
optimal
optimal
solutions
problem
incorporate
optimal
solutions
related
may
solve
slightly
way
arrange
recursive
structure
cutting
view
decomposition
consisting
piece
length
cut
remainder
length
may
further
may
view
every
decomposition
rod
piece
followed
decomposition
couch
solution
no
cuts
saying
piece
has
size
revenue
pn
remainder
has
size
corresponding
revenue
thus
obtain
simpler
version
equation
rn
max
rod
cutting
optimal
solution
embodies
solution
one
related
recursive
implementation
procedure
implements
computation
implicit
equation
recursive
return
return
procedure
takes
input
array
prices
integer
returns
maximum
revenue
possible
rod
length
no
revenue
returns
line
line
initializes
maximum
revenue
loop
lines
correctly
computes
line
returns
simple
induction
proves
answer
equal
desired
answer
using
equation
you
code
your
favorite
programming
language
run
your
you
would
once
input
size
becomes
moderately
your
program
would
take
long
time
you
would
your
program
takes
least
several
likely
you
would
time
you
increase
your
running
time
would
approximately
why
problem
calls
itself
recursively
again
parameter
solves
subproblems
figure
illustrates
happens
calls
calls
process
unfolds
amount
work
function
grows
analyze
running
time
let
denote
total
number
calls
made
called
second
parameter
equal
expression
equals
number
nodes
subtree
whose
root
labeled
recursion
count
includes
initial
call
chapter
dynamic
programming
figure
recursion
tree
showing
recursive
calls
resulting
call
node
label
gives
size
corresponding
edge
parent
label
child
label
corresponds
cutting
initial
piece
size
leaving
remaining
subproblem
size
path
root
leaf
corresponds
one
ways
cutting
rod
length
recursion
tree
has
nodes
initial
call
term
counts
number
calls
recursive
due
call
exercise
asks
you
running
time
exponential
exponential
running
time
plicitly
considers
possible
ways
cutting
rod
length
tree
recursive
calls
has
one
possible
way
cutting
labels
simple
path
root
leaf
give
sizes
remaining
piece
making
labels
give
corresponding
cut
measured
end
using
dynamic
programming
optimal
rod
cutting
now
show
convert
using
dynamic
method
works
having
observed
naive
recursive
solution
because
solves
subproblems
arrange
subproblem
solved
saving
need
refer
solution
again
just
look
rod
cutting
rather
recompute
dynamic
programming
thus
uses
additional
memory
computation
serves
example
savings
may
solution
may
transformed
approach
runs
polynomial
time
number
distinct
subproblems
involved
polynomial
input
size
solve
subproblem
polynomial
usually
two
equivalent
ways
implement
shall
illustrate
both
them
approach
write
procedure
recursively
natural
result
subproblem
array
hash
procedure
now
checks
whether
has
previously
solved
returns
saved
saving
further
computation
procedure
computes
value
usual
say
recursive
procedure
has
results
has
computed
second
approach
approach
typically
depends
natural
notion
solving
any
ticular
subproblem
depends
solving
sort
subproblems
size
solve
them
size
smallest
solving
particular
already
solved
smaller
subproblems
solution
depends
saved
solve
problem
already
solved
prerequisite
two
approaches
yield
algorithms
asymptotic
running
unusual
circumstances
approach
does
actually
recurse
examine
possible
approach
often
has
much
better
constant
has
less
overhead
procedure
pseudocode
ization
let
array
return
word
really
memoization
comes
technique
consists
recording
value
look
chapter
dynamic
programming
else
return
return
main
procedure
initializes
auxiliary
ray
value
convenient
choice
denote
revenue
values
always
calls
helper
procedure
just
memoized
version
previous
checks
line
whether
desired
value
already
known
line
returns
lines
compute
desired
value
usual
line
saves
line
returns
version
even
let
array
return
uses
natural
ordering
problem
size
subproblem
size
procedure
solves
subproblems
sizes
line
procedure
creates
array
results
line
initializes
rod
length
earns
no
lines
solve
subproblem
size
order
increasing
approach
used
solve
problem
particular
size
used
line
now
rod
cutting
figure
subproblem
graph
problem
vertex
labels
give
sizes
corresponding
directed
edge
indicates
need
solution
subproblem
solving
subproblem
graph
reduced
version
tree
figure
nodes
label
collapsed
single
vertex
edges
go
parent
directly
references
array
entry
instead
making
recursive
call
solve
subproblem
size
line
saves
solution
subproblem
size
line
returns
equals
optimal
value
versions
asymptotic
running
running
time
procedure
due
loop
number
iterations
inner
lines
forms
arithmetic
running
time
although
running
time
may
little
harder
because
recursive
call
solve
previously
solved
subproblem
returns
solves
subproblem
just
solves
subproblems
sizes
solve
subproblem
size
loop
lines
iterates
total
number
iterations
recursive
calls
forms
arithmetic
giving
total
just
inner
loop
actually
using
form
aggregate
analysis
shall
aggregate
analysis
detail
section
subproblem
graphs
think
understand
set
subproblems
involved
subproblems
depend
one
subproblem
graph
problem
embodies
exactly
ure
shows
subproblem
graph
problem
directed
containing
one
vertex
distinct
chapter
dynamic
programming
problem
graph
has
directed
edge
vertex
subproblem
vertex
subproblem
determining
optimal
solution
subproblem
involves
directly
optimal
solution
subproblem
problem
graph
contains
edge
recursive
procedure
solving
directly
calls
itself
solve
think
subproblem
graph
version
recursion
tree
sive
coalesce
nodes
subproblem
single
vertex
direct
edges
parent
method
dynamic
programming
considers
vertices
subproblem
graph
order
solve
subproblems
adjacent
given
subproblem
solve
subproblem
section
adjacency
relation
necessarily
using
terminology
chapter
consider
vertices
subproblem
graph
order
topological
sort
section
subproblem
no
subproblem
considered
subproblems
depends
using
notions
view
method
dynamic
programming
subproblem
graph
section
size
subproblem
graph
help
determine
running
time
dynamic
programming
solve
subproblem
just
running
time
sum
times
needed
solve
time
compute
solution
subproblem
proportional
degree
outgoing
corresponding
vertex
subproblem
number
subproblems
equal
number
vertices
problem
common
running
time
dynamic
programming
linear
number
vertices
reconstructing
solution
solutions
problem
return
value
optimal
they
return
actual
list
piece
extend
approach
record
optimal
value
computed
choice
led
optimal
readily
print
optimal
extended
version
rod
size
maximum
revenue
rj
sj
optimal
size
piece
cut
rod
cutting
let
arrays
return
procedure
similar
creates
ray
line
updates
line
hold
optimal
size
piece
cut
solving
subproblem
size
procedure
takes
price
table
rod
size
calls
compute
array
optimal
sizes
prints
out
complete
list
piece
sizes
optimal
decomposition
rod
length
while
print
call
would
return
call
would
print
just
call
would
print
cuts
corresponding
optimal
tion
given
exercises
show
equation
follows
equation
initial
condition
chapter
dynamic
programming
means
strategy
does
always
determine
optimal
way
cut
density
rod
length
pi
value
greedy
strategy
rod
length
cuts
piece
length
having
maximum
continues
applying
greedy
strategy
remaining
piece
length
consider
problem
addition
price
pi
cut
incurs
cost
revenue
associated
solution
now
sum
prices
pieces
costs
making
give
algorithm
solve
modify
return
value
actual
fibonacci
numbers
recurrence
give
algorithm
compute
nth
fibonacci
draw
subproblem
many
vertices
edges
multiplication
example
dynamic
programming
algorithm
solves
problem
given
sequence
ani
matrices
wish
compute
product
evaluate
expression
using
standard
algorithm
ing
pairs
matrices
subroutine
once
parenthesized
resolve
ambiguities
matrices
multiplied
matrix
multiplication
parenthesizations
yield
product
trices
fully
parenthesized
either
single
matrix
product
two
fully
parenthesized
matrix
surrounded
chain
matrices
fully
parenthesize
product
distinct
multiplication
parenthesize
chain
matrices
dramatic
impact
cost
evaluating
consider
cost
multiplying
two
standard
algorithm
given
generalizes
procedure
section
attributes
rows
columns
numbers
rows
columns
error
else
let
matrix
return
cij
cij
cij
ai
bkj
multiply
two
matrices
they
number
columns
must
equal
number
rows
matrix
resulting
matrix
time
compute
dominated
number
scalar
multiplications
line
shall
express
costs
terms
number
scalar
illustrate
different
costs
incurred
different
parenthesizations
matrix
consider
problem
chain
three
suppose
dimensions
matrices
multiply
according
parenthesization
perform
scalar
multiplications
compute
matrix
uct
another
scalar
multiplications
multiply
instead
multiply
matrix
total
scalar
according
parenthesization
perform
scalar
multiplications
compute
matrix
product
another
scalar
multiplications
multiply
total
scalar
computing
product
according
parenthesization
times
state
multiplication
problem
given
chain
ani
matrix
ai
has
dimension
chapter
dynamic
programming
pi
fully
parenthesize
product
way
minimizes
number
scalar
note
multiplication
actually
plying
goal
determine
order
multiplying
matrices
has
lowest
time
invested
determining
optimal
order
paid
time
saved
later
actually
performing
matrix
multiplications
performing
scalar
multiplications
instead
counting
number
parenthesizations
solving
multiplication
problem
dynamic
let
convince
ourselves
exhaustively
checking
possible
parenthesizations
does
yield
denote
number
alternative
sizations
sequence
matrices
just
one
matrix
therefore
one
way
fully
parenthesize
matrix
fully
parenthesized
matrix
product
product
two
fully
sized
matrix
split
two
subproducts
may
occur
kth
matrices
any
obtain
recurrence
problem
asked
you
show
solution
similar
recurrence
sequence
catalan
grows
simpler
exercise
exercise
show
solution
recurrence
number
solutions
thus
exponential
method
exhaustive
search
makes
poor
strategy
determining
optimally
parenthesize
matrix
applying
dynamic
programming
shall
use
method
determine
optimally
parenthesize
matrix
shall
follow
sequence
stated
beginning
characterize
structure
optimal
recursively
value
optimal
compute
value
optimal
multiplication
construct
optimal
solution
computed
shall
go
steps
demonstrating
clearly
apply
step
step
structure
optimal
parenthesization
step
optimal
structure
use
construct
optimal
solution
problem
mal
solutions
multiplication
perform
step
let
adopt
notation
ai
matrix
results
evaluating
product
ai
aj
serve
problem
parenthesize
product
ai
aj
must
split
product
ak
integer
range
value
compute
matrices
ai
multiply
them
together
produce
product
ai
cost
parenthesizing
way
cost
computing
matrix
ai
cost
computing
cost
multiplying
them
optimal
substructure
problem
suppose
timally
parenthesize
ai
aj
split
product
ak
way
parenthesize
subchain
ai
ak
optimal
parenthesization
ai
aj
must
optimal
parenthesization
ai
less
costly
way
parenthesize
ai
could
substitute
parenthesization
optimal
parenthesization
ai
aj
produce
another
way
parenthesize
ai
aj
whose
cost
lower
similar
observation
holds
parenthesize
subchain
aj
optimal
parenthesization
ai
aj
must
optimal
parenthesization
aj
now
use
optimal
substructure
show
construct
optimal
solution
problem
optimal
solutions
seen
any
solution
nontrivial
instance
multiplication
problem
requires
split
any
optimal
solution
contains
timal
solutions
subproblem
build
optimal
solution
instance
multiplication
problem
splitting
problem
two
subproblems
parenthesizing
ai
ak
aj
optimal
solutions
subproblem
combining
timal
subproblem
must
ensure
search
correct
place
split
considered
possible
sure
having
examined
optimal
chapter
dynamic
programming
step
recursive
solution
cost
optimal
solution
recursively
terms
optimal
solutions
multiplication
pick
subproblems
problems
determining
minimum
cost
parenthesizing
ai
aj
let
minimum
number
scalar
multiplications
needed
compute
matrix
ai
full
cost
way
compute
would
thus
recursively
problem
chain
consists
just
one
matrix
ai
no
scalar
multiplications
necessary
compute
compute
take
advantage
structure
optimal
solution
step
let
assume
optimally
split
product
ai
aj
ak
equals
minimum
cost
computing
subproducts
ai
cost
multiplying
two
matrices
recalling
matrix
ai
computing
matrix
product
ai
takes
scalar
obtain
recursive
equation
assumes
know
value
possible
values
namely
optimal
parenthesization
must
use
one
values
need
check
them
recursive
minimum
cost
parenthesizing
product
ai
aj
becomes
min
values
give
costs
optimal
solutions
they
provide
information
need
construct
optimal
help
value
split
product
ai
aj
optimal
equals
value
step
computing
optimal
costs
could
easily
write
recursive
algorithm
based
recurrence
compute
minimum
cost
multiplying
saw
shall
section
recursive
rithm
takes
exponential
no
better
method
checking
way
parenthesizing
multiplication
observe
relatively
few
distinct
one
subproblem
choice
satisfying
recursive
algorithm
may
encounter
subproblem
many
times
different
branches
recursion
property
overlapping
subproblems
second
hallmark
dynamic
programming
applies
hallmark
being
optimal
instead
computing
solution
recurrence
compute
optimal
cost
using
present
sponding
approach
using
memoization
section
shall
implement
method
procedure
appears
procedure
assumes
matrix
ai
input
sequence
has
dimensions
pi
procedure
uses
auxiliary
table
storing
costs
another
auxiliary
table
records
index
achieved
optimal
cost
puting
shall
use
table
construct
optimal
order
implement
must
determine
entries
table
refer
computing
equation
shows
cost
computing
product
matrices
depends
costs
computing
products
fewer
matrix
ai
product
matrices
matrix
product
algorithm
table
manner
corresponds
solving
parenthesization
problem
matrix
chains
increasing
subproblem
optimally
parenthesizing
chain
ai
aj
consider
subproblem
size
length
let
tables
chain
length
return
chapter
dynamic
programming
figure
tables
computed
ing
matrix
matrix
dimension
tables
rotated
main
diagonal
runs
table
uses
main
diagonal
upper
table
uses
upper
minimum
number
scalar
multiplications
multiply
matrices
darker
pairs
shading
taken
together
line
computing
min
algorithm
computes
minimum
costs
chains
length
lines
uses
recurrence
compute
minimum
costs
chains
length
execution
loop
lines
second
time
computes
minimum
costs
chains
length
cost
computed
lines
depends
table
entries
already
figure
illustrates
procedure
chain
portion
table
strictly
main
diagonal
shows
table
rotated
make
main
diagonal
run
matrix
chain
listed
ing
minimum
cost
multiplying
subchain
ai
aj
matrices
intersection
lines
running
northeast
ai
multiplication
northwest
aj
horizontal
row
table
contains
entries
matrix
chains
computes
rows
tom
top
left
right
computes
entry
using
products
entries
southwest
southeast
simple
inspection
nested
loop
structure
yields
running
time
loops
nested
three
loop
index
takes
exercise
asks
you
show
running
time
algorithm
fact
gorithm
requires
space
store
order
much
method
enumerating
possible
parenthesizations
checking
step
constructing
optimal
solution
although
determines
optimal
number
scalar
tiplications
needed
compute
does
directly
show
multiply
table
gives
tion
need
entry
records
value
timal
parenthesization
ai
aj
splits
product
ak
know
matrix
multiplication
computing
optimally
determine
earlier
matrix
multiplications
determines
last
matrix
multiplication
computing
determines
last
matrix
multiplication
puting
recursive
procedure
prints
optimal
sization
given
table
computed
order
indices
initial
call
prints
optimal
parenthesization
print
else
print
print
example
figure
call
prints
parenthesization
chapter
dynamic
programming
exercises
find
optimal
parenthesization
product
whose
sequence
dimensions
give
recursive
algorithm
actually
performs
optimal
given
sequence
matrices
table
computed
dices
initial
call
would
use
substitution
method
show
solution
recurrence
describe
subproblem
graph
multiplication
input
chain
length
many
vertices
does
many
edges
does
edges
let
number
times
table
entry
referenced
while
computing
table
entries
call
show
total
number
references
entire
table
nx
nx
jdi
you
may
equation
show
full
parenthesization
expression
has
exactly
pairs
elements
dynamic
programming
although
just
worked
two
examples
you
might
still
wondering
just
method
gineering
look
solution
examine
two
key
ingredients
elements
dynamic
programming
mization
problem
must
order
dynamic
programming
optimal
substructure
overlapping
revisit
discuss
fully
memoization
might
help
take
advantage
property
recursive
optimal
substructure
step
solving
optimization
problem
dynamic
programming
characterize
structure
optimal
recall
problem
exhibits
optimal
substructure
optimal
solution
problem
contains
mal
solutions
whenever
problem
exhibits
optimal
good
clue
dynamic
programming
might
chapter
might
mean
greedy
strategy
dynamic
build
optimal
solution
problem
optimal
solutions
must
take
care
ensure
range
problems
consider
includes
those
used
optimal
discovered
optimal
substructure
both
problems
examined
chapter
section
observed
optimal
way
ting
rod
length
make
any
cuts
involves
optimally
cutting
two
pieces
resulting
section
observed
optimal
parenthesization
ai
aj
splits
product
ak
contains
optimal
solutions
problems
parenthesizing
ai
ak
aj
you
yourself
common
pattern
discovering
optimal
you
show
solution
problem
consists
making
choosing
initial
cut
rod
choosing
index
split
matrix
making
choice
leaves
one
subproblems
you
suppose
given
you
given
choice
leads
optimal
you
concern
yourself
yet
determine
you
just
assume
has
given
given
you
determine
subproblems
ensue
best
characterize
resulting
space
you
show
solutions
subproblems
used
optimal
solution
problem
must
themselves
optimal
using
you
supposing
subproblem
solutions
optimal
deriving
nonoptimal
solution
subproblem
optimal
you
show
you
get
better
solution
original
thus
ing
your
supposition
you
already
optimal
optimal
chapter
dynamic
programming
solution
gives
rise
one
they
typically
similar
you
modify
argument
one
apply
others
little
characterize
space
good
rule
thumb
says
try
keep
space
simple
possible
expand
space
subproblems
considered
problem
contained
problems
optimally
cutting
rod
length
size
problem
space
worked
no
need
try
general
space
suppose
tried
constrain
subproblem
space
multiplication
matrix
products
form
aj
optimal
parenthesization
must
split
product
ak
unless
could
guarantee
always
equals
would
subproblems
form
ak
aj
latter
subproblem
form
aj
needed
allow
subproblems
vary
allow
both
vary
subproblem
ai
aj
optimal
substructure
varies
problem
domains
two
many
subproblems
optimal
solution
original
problem
many
choices
determining
use
optimal
optimal
solution
cutting
rod
size
uses
just
one
subproblem
size
must
consider
choices
order
determine
one
yields
optimal
tiplication
subchain
ai
aj
serves
example
two
problems
given
matrix
ak
split
two
ai
ak
parenthesizing
aj
must
solve
both
them
once
determine
optimal
solutions
choose
candidates
index
running
time
algorithm
depends
product
two
number
subproblems
overall
many
choices
look
rod
subproblems
choices
examine
yielding
running
multiplication
subproblems
giving
running
time
running
exercise
subproblem
graph
gives
alternative
way
perform
vertex
corresponds
choices
elements
dynamic
programming
problem
edges
incident
recall
rod
subproblem
graph
vertices
edges
yielding
running
draw
problem
would
vertices
vertex
would
degree
giving
total
vertices
dynamic
programming
often
uses
optimal
substructure
optimal
solutions
subproblems
having
solved
optimal
solution
finding
optimal
tion
problem
entails
making
choice
subproblems
use
solving
cost
problem
solution
usually
subproblem
costs
cost
directly
attributable
choice
rod
solved
subproblems
determining
optimal
ways
cut
rods
length
determined
subproblem
yielded
optimal
solution
rod
length
using
equation
cost
attributable
choice
itself
term
pi
tion
determined
optimal
tions
subchains
ai
aj
chose
matrix
ak
split
cost
attributable
choice
itself
term
chapter
shall
examine
many
ities
dynamic
problems
greedy
algorithms
apply
optimal
one
major
difference
greedy
algorithms
dynamic
programming
instead
optimal
solutions
problems
making
informed
greedy
algorithms
make
choice
looks
best
solve
resulting
bothering
solve
possible
related
smaller
cases
strategy
subtleties
you
careful
assume
optimal
substructure
applies
does
consider
two
problems
given
directed
graph
vertices
unweighted
shortest
find
path
consisting
fewest
path
must
removing
cycle
path
duces
path
fewer
use
term
distinguish
problem
shortest
paths
weighted
shall
chapters
use
search
technique
chapter
solve
unweighted
chapter
dynamic
programming
figure
directed
graph
showing
problem
longest
simple
path
unweighted
directed
graph
does
optimal
path
longest
simple
path
subpath
longest
simple
path
nor
subpath
longest
simple
path
unweighted
longest
simple
find
simple
path
consisting
need
include
requirement
simplicity
because
wise
traverse
cycle
many
times
create
paths
arbitrarily
large
number
unweighted
problem
exhibits
optimal
suppose
problem
any
path
must
contain
intermediate
say
may
decompose
path
number
edges
equals
number
edges
number
edges
claim
optimal
path
must
shortest
path
use
another
say
fewer
edges
could
cut
out
paste
produce
path
fewer
edges
thus
contradicting
must
shortest
path
shortest
path
intermediate
vertices
shortest
path
shortest
path
choosing
intermediate
vertex
yields
overall
shortest
section
use
variant
observation
optimal
substructure
shortest
path
every
pair
vertices
directed
you
might
tempted
assume
problem
unweighted
longest
simple
path
exhibits
optimal
substructure
pose
longest
simple
path
longest
simple
path
longest
simple
path
answer
figure
supplies
consider
path
longest
simple
path
longest
simple
path
path
simple
path
longest
simple
path
no
path
simple
path
subpaths
subpaths
elements
dynamic
programming
example
shows
longest
simple
does
problem
lack
optimal
cannot
necessarily
assemble
solution
problem
solutions
combine
longest
simple
paths
get
path
problem
unweighted
longest
simple
path
does
appear
any
sort
optimal
no
algorithm
problem
has
ever
problem
shall
chapter
unlikely
way
solve
polynomial
why
substructure
longest
simple
path
different
est
although
solution
problem
both
longest
shortest
paths
uses
two
subproblems
longest
simple
path
whereas
shortest
paths
they
mean
subproblems
being
mean
solution
one
subproblem
does
affect
solution
another
subproblem
example
ure
problem
longest
simple
path
two
longest
simple
paths
choose
path
used
vertices
no
longer
use
vertices
second
combination
two
solutions
subproblems
would
yield
path
cannot
use
vertex
second
cannot
solve
required
path
vertex
together
subproblem
solutions
vertex
being
because
use
vertices
one
subproblem
cannot
use
them
subproblem
must
use
least
one
them
solve
must
use
both
them
solve
say
subproblems
looked
another
using
resources
solving
one
subproblem
resources
being
renders
them
unavailable
any
shortest
path
subproblems
independent
shortest
answer
subproblems
share
claim
vertex
shortest
path
splice
together
any
produce
shortest
path
shortest
path
assured
no
vertex
appear
both
paths
suppose
vertex
appears
both
pux
optimal
decompose
substructure
path
has
many
edges
say
has
now
let
construct
path
because
excised
paths
contains
least
one
path
contains
contradicts
pux
chapter
dynamic
programming
assumption
shortest
assured
subproblems
problem
both
problems
examined
sections
independent
subproblems
multiplying
subchains
ai
ak
aj
subchains
no
trix
could
possibly
included
both
rod
determine
best
way
cut
rod
length
look
best
ways
cutting
rods
length
because
optimal
solution
problem
includes
just
one
subproblem
solutions
cut
independence
subproblems
overlapping
subproblems
second
ingredient
optimization
problem
must
dynamic
gramming
apply
space
subproblems
must
sense
recursive
algorithm
problem
solves
subproblems
rather
always
generating
total
number
distinct
subproblems
polynomial
input
recursive
rithm
revisits
problem
say
optimization
problem
has
overlapping
problem
conquer
approach
suitable
usually
generates
problems
step
algorithms
typically
take
advantage
overlapping
subproblems
solving
subproblem
once
storing
solution
table
looked
using
constant
time
section
examined
recursive
solution
rod
ting
makes
exponentially
many
calls
solutions
smaller
solution
takes
recursive
algorithm
quadratic
illustrate
property
greater
let
examine
multiplication
referring
back
figure
observe
repeatedly
looks
solution
lems
lower
rows
solving
subproblems
higher
references
entry
four
computations
may
seem
strange
dynamic
programming
relies
subproblems
being
both
independent
although
requirements
may
sound
they
describe
two
different
rather
two
points
two
subproblems
problem
pendent
they
share
two
subproblems
overlapping
they
really
subproblem
occurs
subproblem
different
elements
dynamic
programming
figure
recursion
tree
computation
node
contains
parameters
computations
performed
shaded
subtree
replaced
single
table
lookup
recompute
rather
just
looking
running
time
would
increase
consider
recursive
procedure
determines
mum
number
scalar
multiplications
needed
compute
product
ai
ai
aj
procedure
based
directly
recurrence
return
return
figure
shows
recursion
tree
produced
call
node
labeled
values
parameters
observe
pairs
values
occur
many
show
time
compute
recursive
dure
least
exponential
let
denote
time
taken
compute
optimal
parenthesization
chain
because
execution
lines
lines
take
least
unit
chapter
dynamic
programming
does
multiplication
line
inspection
procedure
yields
recurrence
noting
term
appears
once
once
collecting
summation
together
out
rewrite
recurrence
shall
prove
using
substitution
shall
show
basis
equation
completes
total
amount
work
performed
call
least
exponential
compare
recursive
algorithm
latter
because
takes
advantage
tiplication
has
distinct
algorithm
solves
exactly
recursive
must
again
solve
subproblem
every
time
reappears
recursion
whenever
recursion
tree
natural
recursive
solution
problem
contains
subproblem
total
number
distinct
subproblems
dynamic
programming
improve
sometimes
elements
dynamic
programming
reconstructing
optimal
solution
practical
often
store
choice
made
subproblem
table
reconstruct
information
costs
table
saves
amount
work
reconstructing
optimal
suppose
did
maintain
having
table
containing
optimal
lem
choose
possibilities
determine
subproblems
use
optimal
solution
parenthesizing
ai
aj
would
take
time
struct
subproblems
chose
solution
given
storing
index
matrix
split
product
ai
aj
reconstruct
choice
memoization
saw
alternative
approach
namic
programming
often
offers
programming
approach
while
maintaining
idea
memoize
recursive
maintain
table
subproblem
control
structure
table
recursive
memoized
recursive
algorithm
maintains
entry
table
solution
table
entry
initially
contains
special
value
indicate
entry
has
yet
subproblem
encountered
recursive
algorithm
solution
computed
stored
subsequent
time
encounter
simply
look
value
stored
table
return
memoized
version
note
resembles
memoized
method
approach
presupposes
know
set
possible
subproblem
parameters
established
relationship
table
positions
approach
memoize
using
hashing
subproblem
parameters
chapter
dynamic
programming
let
table
return
else
return
return
maintains
table
computed
values
minimum
ber
scalar
multiplications
needed
compute
matrix
ai
table
entry
initially
contains
value
indicate
entry
has
yet
calling
line
cedure
simply
returns
previously
computed
cost
line
cost
computed
stored
always
returns
value
computes
call
values
figure
illustrates
saves
time
compared
shaded
subtrees
represent
values
looks
rather
algorithm
procedure
runs
line
executes
categorize
calls
two
calls
lines
calls
simply
returns
line
elements
dynamic
programming
calls
one
table
calls
ond
type
made
recursive
calls
calls
whenever
given
call
makes
recursive
makes
calls
second
type
call
second
type
takes
call
type
takes
time
time
spent
recursive
total
memoization
thus
turns
algorithm
solve
multiplication
problem
either
memoized
algorithm
programming
algorithm
both
methods
take
advantage
distinct
subproblems
either
methods
computes
solution
subproblem
natural
recursive
algorithm
runs
exponential
solved
subproblems
repeatedly
general
subproblems
must
solved
least
algorithm
usually
outperforms
corresponding
memoized
algorithm
constant
because
algorithm
has
no
overhead
recursion
less
overhead
maintaining
problems
exploit
regular
pattern
table
accesses
programming
algorithm
reduce
time
space
requirements
even
subproblems
subproblem
space
need
solved
memoized
solution
has
advantage
solving
those
subproblems
exercises
way
determine
optimal
number
multiplications
multiplication
enumerating
ways
ing
product
computing
number
multiplications
running
justify
your
draw
recursion
tree
procedure
section
array
explain
why
memoization
fails
speed
good
algorithm
consider
variant
multiplication
problem
goal
parenthesize
sequence
matrices
rather
chapter
dynamic
programming
number
scalar
does
problem
exhibit
optimal
dynamic
programming
solve
subproblems
choose
them
use
optimal
solution
professor
capulet
claims
always
need
solve
subproblems
order
optimal
she
suggests
optimal
solution
chain
multiplication
problem
always
choosing
matrix
ak
split
subproduct
ai
aj
selecting
minimize
quantity
solving
find
instance
tion
problem
greedy
approach
yields
suboptimal
suppose
problem
section
limit
li
number
pieces
length
allowed
show
property
described
section
no
longer
imagine
you
wish
exchange
one
currency
you
realize
instead
directly
exchanging
one
currency
you
might
better
making
series
trades
winding
currency
you
suppose
you
trade
different
numbered
you
start
currency
wish
wind
currency
you
pair
currencies
exchange
rate
rij
meaning
you
start
units
currency
you
trade
drij
units
currency
sequence
trades
may
entail
depends
number
trades
you
let
ck
commission
you
charged
you
make
show
ck
problem
best
sequence
exchanges
currency
currency
exhibits
optimal
show
commissions
ck
arbitrary
problem
best
sequence
exchanges
currency
currency
does
necessarily
exhibit
optimal
longest
common
subsequence
biological
applications
often
need
compare
dna
two
ferent
strand
dna
consists
string
molecules
called
longest
common
subsequence
possible
bases
representing
bases
initial
express
strand
dna
string
set
appendix
dna
one
organism
may
dna
another
ism
may
one
reason
pare
two
strands
dna
determine
two
strands
measure
closely
related
two
organisms
ilarity
many
different
say
two
dna
strands
similar
one
substring
explores
algorithms
solve
neither
nor
substring
could
say
two
strands
similar
number
changes
needed
turn
one
looks
yet
another
way
measure
similarity
strands
third
strand
bases
appear
bases
must
appear
necessarily
longer
strand
similar
longest
strand
formalize
last
notion
similarity
subsequence
given
sequence
just
given
sequence
zero
elements
left
given
sequence
another
sequence
subsequence
exists
strictly
increasing
sequence
iki
indices
xij
bi
subsequence
bi
corresponding
index
sequence
given
two
sequences
say
sequence
common
sequence
subsequence
both
bi
sequence
ai
common
subsequence
both
sequence
ai
longest
common
subsequence
has
length
sequence
common
both
has
length
sequence
ai
lcs
sequence
no
common
subsequence
length
given
two
sequences
xmi
yni
wish
length
common
subsequence
section
shows
solve
lcs
problem
using
dynamic
chapter
dynamic
programming
step
characterizing
longest
common
subsequence
approach
solving
lcs
would
enumerate
subsequences
check
subsequence
whether
quence
keeping
track
longest
subsequence
subsequence
corresponds
subset
indices
mg
because
has
approach
requires
exponential
making
impractical
long
lcs
problem
has
ing
theorem
shall
natural
classes
subproblems
spond
pairs
two
input
given
sequence
ith
xi
bi
empty
theorem
substructure
let
xmi
yni
let
any
lcs
xm
xm
yn
lcs
xm
xm
implies
lcs
xm
yn
implies
lcs
could
append
xm
yn
obtain
common
proof
subsequence
length
contradicting
supposition
longest
common
subsequence
must
xm
common
subsequence
wish
show
suppose
purpose
contradiction
exists
common
subsequence
length
greater
appending
xm
yn
produces
common
subsequence
whose
length
greater
common
subsequence
common
subsequence
length
greater
would
common
subsequence
xm
contradicting
assumption
lcs
proof
symmetric
way
theorem
characterizes
longest
common
subsequences
tells
lcs
two
sequences
contains
lcs
two
lcs
problem
has
longest
common
subsequence
sive
solution
has
shall
step
recursive
solution
theorem
implies
examine
either
one
two
subproblems
lcs
xmi
xm
must
lcs
appending
xm
yn
lcs
yields
lcs
xm
must
solve
two
lcs
lcs
whichever
two
lcss
longer
lcs
because
cases
exhaust
know
one
optimal
subproblem
solutions
must
appear
lcs
readily
property
lcs
lcs
may
need
lcss
subproblems
has
subsubproblem
lcs
many
subproblems
share
multiplication
recursive
solution
lcs
problem
involves
establishing
recurrence
value
optimal
let
length
lcs
sequences
xi
yj
either
one
sequences
has
length
lcs
has
length
optimal
substructure
lcs
problem
gives
recursive
formula
xi
yj
xi
yj
observe
recursive
condition
problem
restricts
subproblems
may
xi
yj
consider
subproblem
lcs
instead
sider
two
subproblems
lcs
xi
yj
previous
algorithms
rod
cutting
ruled
out
no
subproblems
due
conditions
finding
lcs
algorithm
rules
out
subproblems
based
conditions
problem
problem
has
step
computing
length
lcs
based
equation
could
easily
write
recursive
gorithm
compute
length
lcs
two
lcs
problem
chapter
dynamic
programming
has
distinct
use
dynamic
programming
compute
solutions
bottom
procedure
takes
two
sequences
xmi
yni
stores
values
table
computes
entries
procedure
row
left
second
procedure
maintains
table
help
construct
optimal
points
table
entry
corresponding
optimal
subproblem
solution
chosen
computing
procedure
returns
contains
length
lcs
let
tables
xi
yj
figure
shows
tables
produced
sequences
bi
running
time
procedure
table
entry
takes
time
else
elseif
return
step
constructing
lcs
table
returned
enables
quickly
construct
lcs
xmi
simply
begin
trace
table
whenever
encounter
entry
implies
xi
yj
element
lcs
longest
common
subsequence
xi
yj
figure
tables
computed
sequences
bi
square
row
column
contains
value
appropriate
arrow
value
entry
lower
corner
length
lcs
ai
entry
depends
whether
xi
yj
values
entries
computed
reconstruct
elements
follow
arrows
lower
sequence
shaded
sequence
corresponds
entry
xi
yj
member
encounter
elements
lcs
reverse
recursive
procedure
prints
out
lcs
forward
initial
call
return
print
xi
elseif
else
table
figure
procedure
prints
procedure
takes
time
decrements
least
one
recursive
chapter
dynamic
programming
improving
code
once
you
developed
you
often
you
improve
time
space
changes
simplify
code
improve
constant
factors
otherwise
yield
no
asymptotic
improvement
others
yield
substantial
asymptotic
savings
time
lcs
eliminate
table
entry
depends
three
table
given
value
determine
time
three
values
used
compute
inspecting
table
reconstruct
lcs
time
using
procedure
similar
asks
you
give
although
space
auxiliary
space
requirement
computing
lcs
does
asymptotically
need
space
table
reduce
asymptotic
space
requirements
needs
two
rows
table
row
being
computed
previous
exercise
asks
you
use
slightly
space
one
row
compute
length
improvement
works
need
length
need
reconstruct
elements
smaller
table
does
keep
enough
information
retrace
steps
exercises
determine
lcs
give
pseudocode
reconstruct
lcs
completed
table
original
sequences
xmi
yni
using
give
memoized
version
runs
show
compute
length
lcs
using
entries
table
additional
show
using
entries
additional
optimal
binary
search
trees
give
algorithm
longest
monotonically
increasing
quence
sequence
give
lg
algorithm
longest
monotonically
increasing
sequence
sequence
observe
last
element
candidate
subsequence
length
least
large
last
element
didate
subsequence
length
maintain
candidate
subsequences
linking
them
input
optimal
binary
search
trees
suppose
designing
program
translate
text
english
occurrence
english
word
need
look
french
could
perform
lookup
operations
building
binary
search
tree
english
words
keys
french
equivalents
satellite
because
search
tree
individual
word
want
total
time
spent
searching
low
could
ensure
search
time
occurrence
using
tree
any
balanced
binary
search
words
appear
different
frequently
used
word
may
appear
far
root
while
rarely
used
word
machicolation
appears
organization
would
slow
number
nodes
visited
searching
key
binary
search
tree
equals
one
depth
node
containing
want
words
occur
frequently
text
placed
nearer
words
text
might
no
french
words
would
appear
binary
search
tree
organize
binary
search
tree
minimize
number
nodes
visited
given
know
often
word
need
known
optimal
binary
search
given
sequence
kni
distinct
keys
sorted
order
wish
build
binary
search
tree
key
ki
probability
pi
search
ki
searches
may
values
subject
text
castle
might
want
machicolation
appear
machicolation
has
french
chapter
dynamic
programming
figure
two
binary
search
trees
set
keys
pi
qi
binary
search
tree
expected
search
cost
binary
search
tree
expected
search
cost
tree
dn
representing
values
represents
ues
less
dn
represents
values
greater
dummy
key
di
represents
values
ki
dummy
key
probability
qi
search
correspond
figure
shows
two
binary
search
trees
set
key
ki
internal
dummy
key
di
every
search
either
successful
key
ki
unsuccessful
dummy
key
qi
nx
pi
nx
because
probabilities
searches
key
dummy
determine
expected
cost
search
given
binary
search
tree
let
assume
actual
cost
search
equals
number
nodes
depth
node
found
search
expected
cost
search
cost
nx
nx
pi
nx
deptht
pi
nx
deptht
qi
qi
optimal
binary
search
trees
deptht
denotes
depth
tree
last
equality
follows
equation
figure
calculate
expected
search
cost
node
node
total
depth
probability
contribution
given
set
wish
construct
binary
search
tree
whose
expected
search
cost
call
tree
optimal
binary
search
figure
shows
optimal
binary
search
tree
probabilities
given
expected
cost
example
shows
optimal
binary
search
tree
necessarily
tree
whose
overall
height
nor
necessarily
construct
optimal
binary
search
tree
always
putting
key
greatest
probability
key
has
greatest
search
probability
any
yet
root
optimal
binary
search
tree
lowest
expected
cost
any
binary
search
tree
root
exhaustive
checking
possibilities
fails
yield
label
nodes
any
binary
tree
keys
kn
construct
binary
search
add
dummy
keys
problem
saw
number
binary
trees
nodes
would
examine
exponential
number
binary
search
trees
exhaustive
shall
solve
problem
dynamic
step
structure
optimal
binary
search
tree
characterize
optimal
substructure
optimal
binary
search
start
observation
consider
any
subtree
binary
search
must
contain
keys
contiguous
range
ki
kj
subtree
contains
keys
ki
kj
must
leaves
dummy
keys
dj
now
state
optimal
optimal
binary
search
tree
has
subtree
containing
keys
ki
kj
subtree
must
optimal
chapter
dynamic
programming
subproblem
keys
ki
kj
dummy
keys
dj
usual
argument
subtree
whose
expected
cost
lower
could
cut
out
paste
resulting
binary
search
tree
lower
expected
cost
thus
contradicting
optimality
need
use
optimal
substructure
show
construct
mal
solution
problem
optimal
solutions
given
keys
ki
kj
one
say
kr
root
optimal
subtree
containing
left
subtree
root
kr
contains
keys
ki
dummy
keys
right
subtree
contains
keys
kj
dummy
keys
dr
dj
long
examine
date
roots
determine
optimal
binary
search
trees
containing
ki
those
containing
kj
guaranteed
optimal
binary
search
one
detail
worth
noting
suppose
subtree
keys
ki
kj
select
ki
left
subtree
contains
keys
ki
interpret
sequence
containing
no
bear
subtrees
contain
dummy
adopt
convention
subtree
containing
keys
ki
has
no
actual
keys
does
contain
single
dummy
key
select
kj
kj
right
subtree
contains
keys
kj
right
subtree
contains
no
actual
does
contain
dummy
key
dj
step
recursive
solution
ready
value
optimal
solution
pick
subproblem
domain
optimal
binary
search
tree
containing
keys
ki
kj
no
actual
just
dummy
key
let
expected
cost
searching
optimal
binary
search
tree
containing
keys
ki
kj
wish
compute
easy
case
occurs
just
dummy
key
expected
search
cost
need
select
root
kr
ki
kj
make
optimal
binary
search
tree
keys
ki
left
subtree
optimal
binary
search
tree
keys
kj
right
happens
expected
search
cost
subtree
becomes
subtree
depth
node
subtree
increases
equation
expected
search
cost
subtree
increases
sum
probabilities
subtree
keys
ki
kj
let
denote
sum
probabilities
optimal
binary
search
trees
jx
pl
jx
ql
ldi
kr
root
optimal
subtree
containing
keys
ki
kj
pr
noting
pr
rewrite
recursive
equation
assumes
know
node
kr
use
choose
root
gives
lowest
expected
search
giving
recursive
min
values
give
expected
search
costs
optimal
binary
search
help
keep
track
structure
optimal
binary
search
index
kr
root
optimal
binary
search
tree
containing
keys
ki
kj
although
compute
values
leave
construction
optimal
binary
search
tree
values
exercise
step
computing
expected
search
cost
optimal
binary
search
tree
you
may
noticed
similarities
characterizations
optimal
binary
search
trees
both
problem
subproblems
consist
contiguous
index
sive
implementation
equation
would
sive
multiplication
store
values
table
nc
index
needs
run
nc
rather
because
order
subtree
containing
dummy
key
need
compute
store
second
index
needs
start
because
order
subtree
containing
dummy
key
need
compute
store
use
entries
use
table
recording
root
subtree
containing
keys
ki
kj
table
uses
entries
need
one
table
rather
compute
value
scratch
every
time
computing
would
take
chapter
dynamic
programming
store
values
table
base
compute
compute
pj
qj
compute
values
time
pseudocode
follows
takes
inputs
probabilities
pn
qn
size
returns
tables
let
tables
pj
qj
return
root
description
similarity
cedure
section
you
operation
procedure
fairly
loop
lines
initializes
values
loop
lines
uses
recurrences
compute
loop
computes
ond
computes
innermost
lines
tries
candidate
index
determine
key
kr
use
root
optimal
binary
search
tree
taining
keys
ki
kj
loop
saves
current
value
index
whenever
better
key
use
figure
shows
tables
computed
procedure
key
distribution
figure
multiplication
example
figure
tables
rotated
make
optimal
binary
search
trees
root
figure
tables
computed
key
distribution
figure
tables
rotated
diagonals
run
diagonals
run
computes
rows
bottom
top
left
right
procedure
takes
just
easily
running
time
loops
nested
three
deep
loop
index
takes
loop
indices
exactly
bounds
those
they
procedure
takes
exercises
write
pseudocode
procedure
given
table
outputs
structure
optimal
binary
search
example
figure
your
procedure
print
out
structure
chapter
dynamic
programming
root
left
child
left
child
right
child
right
child
left
child
left
child
left
child
right
child
right
child
right
child
corresponding
optimal
binary
search
tree
figure
determine
cost
structure
optimal
binary
search
tree
set
keys
pi
qi
suppose
instead
maintaining
table
computed
value
directly
equation
line
used
computed
value
line
would
change
affect
asymptotic
running
time
knuth
has
always
roots
optimal
subtrees
use
fact
modify
procedure
run
problems
longest
simple
path
directed
acyclic
graph
suppose
given
directed
acyclic
graph
valued
edge
weights
two
distinguished
vertices
describe
programming
approach
longest
weighted
simple
path
does
subproblem
graph
look
your
problems
chapter
figure
seven
points
unit
shortest
closed
length
approximately
tour
shortest
bitonic
tour
set
length
approximately
longest
palindrome
subsequence
palindrome
nonempty
string
alphabet
reads
ward
examples
palindromes
strings
length
aibohphobia
give
algorithm
longest
palindrome
subsequence
given
input
given
input
your
algorithm
return
running
time
your
bitonic
euclidean
problem
euclidean
given
set
points
wish
shortest
closed
tour
connects
figure
shows
solution
general
problem
solution
therefore
believed
require
polynomial
time
chapter
bentley
has
suggested
simplify
problem
restricting
tention
bitonic
tours
start
leftmost
go
strictly
rightward
rightmost
go
strictly
leftward
back
starting
figure
shows
shortest
bitonic
tour
algorithm
describe
algorithm
determining
optimal
bitonic
you
may
assume
no
two
points
operations
real
numbers
take
unit
scan
left
maintaining
optimal
sibilities
two
parts
printing
neatly
consider
problem
neatly
printing
paragraph
monospaced
font
characters
having
input
text
sequence
chapter
dynamic
programming
words
lengths
measured
want
print
graph
neatly
number
lines
hold
maximum
characters
criterion
given
line
contains
words
leave
exactly
one
space
number
extra
space
characters
end
line
kdi
must
nonnegative
words
wish
minimize
lines
cubes
numbers
extra
space
characters
ends
give
algorithm
print
paragraph
words
neatly
analyze
running
time
space
requirements
your
edit
distance
order
transform
one
source
string
text
target
string
perform
various
transformation
goal
given
produce
series
transformations
change
use
ray
large
enough
hold
characters
hold
intermediate
maintain
current
indices
operations
allowed
alter
required
examine
every
character
means
end
sequence
transformation
must
may
choose
six
transformation
copy
character
setting
incrementing
both
operation
examines
replace
character
another
character
setting
incrementing
both
operation
examines
delete
character
incrementing
leaving
operation
examines
insert
character
setting
incrementing
leaving
operation
examines
no
characters
twiddle
two
characters
copying
them
setting
setting
operation
examines
kill
remainder
setting
operation
examines
acters
yet
must
problems
chapter
one
way
transform
source
string
algorithm
target
string
altruistic
use
sequence
underlined
characters
operation
initial
strings
copy
copy
replace
delete
copy
insert
insert
insert
twiddle
insert
kill
algorithm
algorithm
algorithm
algorithm
algorithm
algorithm
algorithm
algorithm
algorithm
algorithm
algorithm
algorithm
alt
alt
altr
altru
altrui
altruis
altruisti
altruistic
altruistic
note
several
sequences
transformation
operations
form
algorithm
transformation
operations
has
associated
cost
operation
depends
assume
cost
constant
known
assume
individual
costs
copy
replace
operations
less
combined
costs
delete
insert
copy
replace
operations
would
cost
given
sequence
transformation
operations
sum
costs
individual
operations
sequence
cost
transforming
algorithm
altruistic
given
two
sequences
set
edit
distance
cost
least
expensive
operation
sequence
transforms
describe
algorithm
edit
distance
prints
optimal
eration
analyze
running
time
space
requirements
your
problem
generalizes
problem
aligning
two
dna
sequences
setubal
meidanis
section
several
methods
measuring
similarity
two
dna
sequences
aligning
one
method
align
two
sequences
consists
inserting
spaces
chapter
dynamic
programming
arbitrary
locations
two
sequences
either
ing
sequences
length
space
position
no
position
both
assign
position
receives
score
neither
neither
either
score
alignment
sum
scores
individual
given
sequences
gatcggcat
one
alignment
atcg
gcat
caat
gtgaatc
position
indicates
score
indicates
score
indicates
score
alignment
has
total
score
explain
cast
problem
optimal
alignment
edit
distance
problem
using
subset
transformation
operations
planning
company
party
professor
stewart
consulting
president
corporation
planning
company
company
has
hierarchical
supervisor
relation
forms
tree
rooted
personnel
has
ranked
employee
conviviality
real
order
make
party
fun
president
does
want
both
employee
immediate
supervisor
professor
stewart
given
tree
describes
structure
using
representation
described
section
node
tree
addition
name
employee
conviviality
describe
algorithm
make
guest
list
maximizes
sum
conviviality
ratings
analyze
running
time
your
viterbi
algorithm
use
dynamic
programming
directed
graph
speech
edge
labeled
sound
nite
set
labeled
graph
formal
model
person
speaking
problems
chapter
restricted
path
graph
starting
distinguished
tex
corresponds
possible
sequence
sounds
produced
label
directed
path
concatenation
labels
edges
describe
algorithm
given
graph
tinguished
vertex
sequence
sounds
returns
path
begins
has
any
path
algorithm
return
analyze
running
time
your
you
may
concepts
chapter
suppose
every
edge
has
associated
nonnegative
bility
traversing
edge
vertex
thus
producing
corresponding
sum
probabilities
edges
leaving
any
vertex
equals
probability
path
product
ities
view
probability
path
beginning
probability
beginning
follow
randomly
choose
edge
take
leaving
vertex
according
probabilities
available
edges
leaving
extend
your
answer
part
path
able
path
starting
having
label
analyze
running
time
your
image
compression
seam
carving
given
color
picture
consisting
array
pixel
triple
blue
pose
wish
compress
picture
wish
remove
one
pixel
whole
picture
becomes
one
pixel
avoid
disturbing
visual
require
pixels
removed
two
adjacent
rows
adjacent
pixels
moved
form
top
row
bottom
row
successive
pixels
seam
adjacent
vertically
show
number
possible
seams
grows
least
exponentially
assuming
suppose
now
pixel
calculated
valued
disruption
measure
indicating
disruptive
would
remove
pixel
lower
disruption
similar
pixel
suppose
further
disruption
measure
seam
sum
disruption
measures
chapter
dynamic
programming
give
algorithm
seam
lowest
disruption
your
breaking
string
certain
language
allows
programmer
break
string
two
because
operation
copies
costs
time
units
break
string
characters
two
suppose
programmer
wants
break
string
many
order
breaks
occur
affect
total
amount
time
suppose
programmer
wants
break
string
characters
characters
ascending
order
starting
she
programs
breaks
occur
break
costs
time
second
break
costs
time
units
string
characters
character
third
break
costs
time
totaling
time
she
programs
breaks
occur
break
costs
time
second
break
costs
time
third
break
costs
time
totaling
time
yet
another
she
could
break
break
left
piece
right
piece
total
cost
design
algorithm
given
numbers
characters
determines
way
sequence
those
given
string
characters
array
containing
break
pute
lowest
cost
sequence
sequence
breaks
achieves
planning
investment
strategy
your
knowledge
algorithms
helps
you
obtain
exciting
job
acme
computer
signing
you
decide
invest
money
goal
maximizing
your
return
end
you
decide
use
amalgamated
investment
company
manage
your
amalgamated
investments
requires
you
observe
offers
different
numbered
year
investment
provides
return
rate
rij
you
invest
dollars
investment
year
end
year
you
drij
return
rates
you
given
return
rates
years
you
make
investment
decisions
once
end
you
leave
money
made
previous
year
you
shift
money
either
shifting
money
existing
investments
moving
money
you
move
your
money
two
consecutive
you
pay
fee
whereas
you
switch
your
you
pay
fee
problems
chapter
allows
you
invest
your
money
multiple
investments
prove
exists
optimal
investment
strategy
puts
money
single
optimal
investment
strategy
maximizes
amount
money
years
concerned
any
minimizing
prove
problem
planning
your
optimal
investment
strategy
exhibits
optimal
design
algorithm
plans
your
optimal
investment
running
time
your
suppose
amalgamated
investments
imposed
additional
restriction
any
you
no
any
one
show
problem
maximizing
your
income
end
years
no
longer
exhibits
optimal
inventory
planning
rinky
dink
company
makes
machines
resurface
ice
demand
products
varies
month
company
needs
velop
strategy
plan
manufacturing
given
company
wishes
design
plan
month
company
knows
demand
di
number
machines
let
di
total
demand
company
keeps
staff
who
provide
labor
manufacture
chines
company
needs
make
machines
given
hire
cost
works
out
dollars
end
company
holding
any
unsold
must
pay
inventory
cost
holding
machines
given
function
give
algorithm
calculates
plan
company
minimizes
costs
while
running
time
polyomial
signing
baseball
players
suppose
you
general
manager
baseball
you
need
sign
players
your
team
owner
has
given
you
budget
spend
free
you
allowed
spend
less
owner
you
you
spend
any
chapter
dynamic
programming
you
different
players
who
play
position
because
you
want
overload
your
roster
too
many
players
any
position
you
may
sign
one
free
agent
who
plays
you
sign
any
players
particular
you
plan
stick
players
you
already
determine
valuable
player
going
you
decide
use
ric
known
replacement
player
higher
vorp
valuable
player
lower
player
higher
vorp
necessarily
expensive
sign
player
lower
because
factors
value
determine
much
costs
sign
available
you
three
pieces
amount
money
cost
sign
devise
algorithm
maximizes
total
vorp
players
you
sign
while
spending
no
you
may
assume
player
signs
multiple
your
algorithm
output
total
vorp
players
you
total
amount
money
you
list
players
you
analyze
running
time
space
requirement
your
chapter
notes
bellman
began
systematic
study
dynamic
programming
word
both
linear
refers
using
ular
solution
although
optimization
techniques
incorporating
elements
dynamic
programming
known
bellman
provided
area
solid
mathematical
basis
nine
positions
baseball
necesarily
equal
because
general
managers
particular
ways
thinking
general
manager
might
consider
pitchers
pitchers
separate
starting
long
relief
pitchers
pitchers
who
pitch
several
short
relief
pitchers
pitchers
who
normally
pitch
one
application
statistical
analysis
baseball
provides
several
ways
compare
relative
values
individual
notes
chapter
galil
park
classify
algorithms
according
size
table
number
table
entries
entry
depends
they
call
algorithm
table
size
entry
depends
multiplication
algorithm
section
would
algorithm
section
would
hu
shing
give
lg
algorithm
multiplication
algorithm
problem
pears
folk
knuth
posed
question
whether
subquadratic
algorithms
lcs
problem
masek
paterson
answered
question
giving
algorithm
runs
lg
sequences
drawn
set
bounded
special
case
no
element
appears
once
input
szymanski
shows
solve
problem
many
results
extend
problem
computing
string
edit
distances
early
paper
binary
encodings
gilbert
moore
applications
constructing
optimal
binary
search
trees
case
probabilities
pi
paper
contains
ullman
present
algorithm
section
exercise
due
knuth
hu
tucker
devised
algorithm
case
probabilities
pi
uses
time
knuth
reduced
time
lg
problem
due
avidan
shamir
who
posted
web
wonderful
video
illustrating